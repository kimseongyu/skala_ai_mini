{
  "timestamp": "20250520_012148",
  "data": {
    "AI": [
      "artificial intelligence",
      "AI Thinking",
      "symbolic AI",
      "subsymbolic AI",
      "Intersymbolic AI",
      "AI transparency",
      "uncertainty",
      "AI's confidence level",
      "AI/ML Security Workers",
      "Adversarial Techniques",
      "AI/ML ATT&CK framework",
      "AI/ML fairness",
      "AI Ethics",
      "AI Readiness",
      "AI integration",
      "AI adoption",
      "AI-CAM",
      "AI Capabilities Matrix",
      "machine learning",
      "semantic technologies",
      "human-AI collaborative decision-making",
      "explainable AI (XAI)",
      "human-AI interaction",
      "AI system for stroke rehabilitation assessment"
    ],
    "LLM": [
      "large language models",
      "databases",
      "LLM-integrated applications",
      "software engineering",
      "LLM components",
      "Parrot",
      "Semantic Variable",
      "LLM service system",
      "Code LLMs",
      "LLM Online Spatial-temporal Reconstruction",
      "Graph Signal Processing",
      "GPT-4-o mini",
      "asynchronous LLM function calling",
      "AsyncLM",
      "interrupt mechanism",
      "in-context protocol",
      "Berkeley function calling leaderboard",
      "Multi-LLM Text Summarization",
      "multi-LLM decentralized summarization",
      "multi-LLM centralized summarization",
      "LLM-based generative graph analytics",
      "LLM-based graph query processing",
      "knowledge graph",
      "graph-LLM-based applications",
      "LLM-as-a-Judge",
      "RLHF",
      "DPO",
      "alignment tasks",
      "TL;DR Summarization",
      "HH-RLHF-Helpfulness"
    ],
    "LLVM": [
      "IRFuzzer",
      "LLVM compiler backend",
      "constrained mutations",
      "feedback quality",
      "mutator",
      "instrumentation",
      "matcher table coverage",
      "architecture specific guidance",
      "Traversal of Layers",
      "large language models",
      "visual instruction tuning",
      "vision language performances",
      "natural language instructions",
      "layer traversing technique",
      "forward propagation layers",
      "Phantom",
      "latent hidden dimension",
      "multi-head self-attention",
      "Phantom Optimization",
      "autoregressive supervised fine-tuning",
      "direct preference optimization",
      "Mixture of All Intelligence",
      "instruction-tuned large language and vision models",
      "vision language data",
      "visual perception tasks",
      "segmentation",
      "detection",
      "scene graph generation",
      "optical character recognition",
      "MoAI-Compressor",
      "MoAI-Mixer",
      "Mixture of Experts"
    ]
  }
}